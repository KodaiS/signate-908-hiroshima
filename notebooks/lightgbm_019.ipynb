{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNN9iNPFkPI5hzKiZsBl9Zk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# IMNKさんのベースラインを参考に\n","https://signate.jp/competitions/908/discussions/lightgbm-4?comment_id=6220#6220"],"metadata":{"id":"jQclsB18g2DD"}},{"cell_type":"code","source":["# driveのマウント\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wy_b5StDg-eF","executionInfo":{"status":"ok","timestamp":1673361702847,"user_tz":-540,"elapsed":4197,"user":{"displayName":"Kodai Shimizu","userId":"11388889893078731648"}},"outputId":"c544e637-8093-4968-bb1b-56f930f39c57"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# モジュールのインポート\n","import os\n","import copy\n","import pandas as pd\n","import numpy as np\n","import math\n","import pickle\n","import lightgbm as lgb\n","import itertools as it\n","from sklearn.model_selection import GroupKFold\n","from sklearn.preprocessing import StandardScaler"],"metadata":{"id":"friN1QwmhK3k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 作業用ディレクトリ\n","os.chdir('/content/drive/MyDrive/signate-908-hiroshima/')\n","my_dir = os.getcwd()"],"metadata":{"id":"F392hYcbhSnM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 設定"],"metadata":{"id":"nJr0R3TSkbYP"}},{"cell_type":"code","source":["class Config:\n","    given_dir = os.path.join(my_dir, 'data', 'given') #ダウンロードしてきたデータのディレクトリ\n","    data_dir = os.path.join(my_dir, 'data', 'preprocess') #前加工済のデータのディレクトリ\n","    model_dir = os.path.join(my_dir, 'model') #モデルの格納ディレクトリ\n","    encoding = 'CP932' #CSV保存時の文字コード\n","    nrows = None #CSVの読み込み行数　→ 全データの時はNone、試しにコードを動かす時は、10万件などにする\n","    model_ver = '0_19' #モデルのバージョン番号\n","    th_per = 0.2 # テスト用データの割合　→20%に設定\n","    fold = 3 # 交差検証の分割数\n","    \n","    # LightGBMのハイパーパラメータを設定\n","    lgb_params = {\n","              'objective': 'regression',    # 回帰を指定\n","              'metric': 'rmse', # 関数はRMSEを使用\n","              }\n","\n","my_config = Config()"],"metadata":{"id":"qMAAEnPwhdLx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 前処理"],"metadata":{"id":"Zl3KwOtUkeex"}},{"cell_type":"code","source":["# waterlevel前処理用の関数定義\n","\n","def preprocess_water_data_station(water_data, water_stations):\n","    \"\"\"water_dataの観測所名称を修正\n","    \"\"\"\n","    # 欠損値補完\n","    water_data['river'] = water_data['river'].replace('\\u3000', '沼田川')\n","\n","    # (国)への変更前観測所名を変換\n","    stations = water_data.loc[water_data['station'].str.contains(r'\\(国\\)'), 'station'].unique()\n","    # 中野、伊尾、和木は(国)を含まない観測所が別途存在するため別処理\n","    stations = [x.replace('(国)', '') for x in stations if x not in ['中野(国)', '伊尾(国)', '和木(国)']]\n","    water_data['station'] = water_data['station'].apply(lambda x: x + '(国)' if x in stations else x)\n","    # 中野、伊尾、和木は河川名で分けて処理\n","    water_data.loc[(water_data['station']=='中野')&(water_data['river']=='太田川'), 'station'] = '中野(国)'\n","    water_data.loc[(water_data['station']=='伊尾')&(water_data['river']=='芦田川'), 'station'] = '伊尾(国)'\n","    water_data.loc[(water_data['station']=='和木')&(water_data['river']=='小瀬川'), 'station'] = '和木(国)'\n","\n","    # (電)への変更前観測所名を変換\n","    stations = water_data.loc[water_data['station'].str.contains(r'\\(電\\)'), 'station'].unique()\n","    stations = [x.replace('(電)', '') for x in stations]\n","    water_data['station'] = water_data['station'].apply(lambda x: x + '(電)' if x in stations else x)\n","\n","    # 入力ミスと思われるもの\n","    water_data['station'] = water_data['station'].replace({'藤波': '藤浪',\n","                                                           '中州橋': '中洲橋',\n","                                                           '段原': '段原(猿猴川)'})\n","    water_data['river'] = water_data['river'].replace({'手越川': '手城川',\n","                                                       '横川': '横川川'})\n","\n","    # 入力時使用外の観測所を削除\n","    in_stations = water_stations.loc[water_stations['入力時使用']==1, '観測所名称'].unique()\n","    water_data = water_data[water_data['station'].isin(in_stations)]\n","    water_stations = water_stations[water_stations['入力時使用']==1]\n","\n","    return water_data, water_stations\n","\n","\n","def fill_wl_nan(df, station_pair):\n","    \"\"\"欠損値を他の観測所の値を使って埋める\n","    互いに標準化した値でNaNを埋めて、元のスケールに戻す\n","    \"\"\"\n","\n","    for k, v in station_pair.items():\n","        scaler_k = StandardScaler()\n","        scaler_v = StandardScaler()\n","        \n","        value_k = df.loc[df['station']==k, ['value']]\n","        value_v = df.loc[df['station']==v, ['value']]\n","\n","        scaler_k.fit(value_k.values)\n","        scaler_v.fit(value_v.values)\n","\n","        value_k = scaler_k.transform(value_k.values)\n","        value_v = scaler_v.transform(value_v.values)\n","\n","        value_k[np.isnan(value_k)] = value_v[np.isnan(value_k)]\n","        df.loc[df['station']==k, ['value']] = scaler_k.inverse_transform(value_k)\n","\n","    return df"],"metadata":{"id":"t1K-nUgHqZMp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# waterlevelの読み込み\n","data_dir = os.path.join(my_config.given_dir, 'waterlevel/data.csv')\n","data = pd.read_csv(data_dir, encoding='utf8')\n","data_dir = os.path.join(my_config.given_dir, 'waterlevel/stations.csv')\n","station_mst = pd.read_csv(data_dir, encoding='utf8')"],"metadata":{"id":"NqAuLmZMHWTc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# waterlevelの観測所の変更を修正\n","data, station_mst = preprocess_water_data_station(data, station_mst)"],"metadata":{"id":"WFRBeV85HYfs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# waterlevelデータの加工\n","# 河川名の列は削除\n","data.drop(\"river\", axis=1, inplace=True)\n","# 行列を転置させる\n","data.set_index(['date', 'station'], inplace=True)\n","data = data.stack().reset_index(drop=False)\n","data.columns = [\"date\", \"station\", \"hour\", \"value\"]\n","# 時間帯をint形式に変換\n","data[\"hour\"] = data[\"hour\"].str[:2].astype(int)"],"metadata":{"id":"DQBToiL4iRu8","executionInfo":{"status":"ok","timestamp":1673361709790,"user_tz":-540,"elapsed":4733,"user":{"displayName":"Kodai Shimizu","userId":"11388889893078731648"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bf11b7d1-51bf-44d0-ba94-9bd091a60c0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  return super().drop(\n"]}]},{"cell_type":"code","source":["# 水位データを数値に変換\n","data['value'] = pd.to_numeric(data['value'], errors='coerce')\n","# 明らかな外れ値を修正\n","data.loc[(data['station']=='山手左岸(国)')&(data['value']<-90), 'value'] = 0\n","data.loc[data['station']=='七社', 'value'] = data.loc[data['station']=='七社', 'value'].apply(lambda x: round(x / 10, 2) if x > 9 else x)\n","\n","# NaNを他の観測所のデータから補完\n","fillnan_pair = {\n","    '竹の花(国)': '上安田(国)',  # 同水系で相関が強く地理的にも近いもの\n","    '新市(国)': '上戸手(国)',  # 同水系で相関が強く地理的にも近いもの\n","    '駅前': '伊尾(国)',\n","    '上庄(国)': '中深川(国)',\n","    '市原': '新庄', # 相関が強いもの　候補 '今津', '新庄', '三津', '風早'\n","    }\n","data = fill_wl_nan(data, fillnan_pair)"],"metadata":{"id":"H17rfrmBGtbr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 保存する\n","if os.path.exists(os.path.join(my_config.data_dir, \"waterlevel\"))==False:\n","    os.makedirs(os.path.join(my_config.data_dir, \"waterlevel\"))\n","    \n","data.to_csv(os.path.join(my_config.data_dir, \"waterlevel\", \"data.csv\"),\n","            index=False,\n","            encoding=my_config.encoding)"],"metadata":{"id":"LnZJ-pIzjF_h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 観測所マスタの作成\n","# データを読み込む\n","# 観測所に連番を振っておく\n","# SJISで保存\n","# 不要なカラムは削除\n","station_mst.drop(['フリガナ', \"事務所\", \"データ所管\", \"住所\", \"入力時使用\"], axis=1, inplace=True)"],"metadata":{"id":"XsBmEUGCjF5A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 観測所に連番を振る\n","station_list = station_mst[['観測所名称']].drop_duplicates()\n","station_list['station_id'] = range(1, len(station_list.index)+1)\n","station_list.reset_index(drop=True, inplace=True)\n","station_mst = pd.merge(station_mst, station_list, on=['観測所名称'], how='left').sort_values('station_id')\n","# 列名を変更する\n","station_mst.rename(columns={\"河川名\":\"river\", \"観測所名称\":\"station\", \"市町\":\"city\", \"評価対象\":'review_tgt'}, inplace=True)"],"metadata":{"id":"ronmj4uMjFzK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 保存する\n","station_mst.to_csv(os.path.join(my_config.data_dir, 'waterlevel', 'station_master.csv'),\n","                   encoding=my_config.encoding, index=False)"],"metadata":{"id":"rCORIIPliUdU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### クラスを定義"],"metadata":{"id":"aWI9Ay3ei0Yh"}},{"cell_type":"code","source":["class ScoringService(object):\n","    first_flg = True\n","    # predict時に参照するConfig\n","    # Configを上書きする時は、get_configを使用する\n","    class Config:\n","        nrows = None\n","        fold = 3\n","        model_ver = '0_19'\n","        encoding = 'CP932'\n","    config = Config()\n","\n","    @classmethod\n","    # Configを再取得するメソッド\n","    def get_config(cls, config):\n","        try:\n","            cls.config = config\n","            return True\n","        except:\n","            return False        \n","\n","    @classmethod\n","    # モデルを取得するメソッド\n","    # 交差検証しているため、モデルはリスト(cls.models)に格納される\n","    def get_model(cls, model_path):\n","        try:\n","            cls.models = []\n","            for i in range(cls.config.fold):\n","                model = pickle.load(open(os.path.join(model_path,\n","                    'trained_model_' + cls.config.model_ver + '_fold_' + str(i) + '.pkl'), 'rb'))\n","                cls.models.append(model)\n","            return True\n","        except:\n","            return False\n","\n","    @classmethod\n","    # 予測用のデータを取得する関数\n","    def get_store_data(cls, data_path):\n","        try:\n","            # 観測所マスタと予測対象の読み込み\n","            cls.station_mst = pd.read_csv(os.path.join(data_path, 'waterlevel', 'station_master.csv'), encoding=cls.config.encoding)\n","            cls.review_tgt = cls.station_mst.loc[cls.station_mst[\"review_tgt\"]==1,\"station\"].values\n","            # 水位データの読み込み\n","            cls.wl_data = pd.read_csv(os.path.join(data_path, 'waterlevel', 'data.csv'),nrows=cls.config.nrows, encoding='CP932')\n","            # 評価対象の観測所のみを読み込む\n","            cls.wl_data = cls.wl_data.loc[cls.wl_data[\"station\"].isin(cls.review_tgt)]\n","            # 取得したデータを並べ替え、欠損値を埋める\n","            cls.wl_data['value'] = cls.wl_data['value'].replace({'M':np.nan, '*':np.nan, '-':np.nan, '--': np.nan, '**':np.nan}).astype(float)\n","            cls.wl_data.sort_values(['station', 'date', 'hour'], inplace=True)\n","            cls.wl_data['value'] = cls.wl_data.groupby('station')['value'].fillna(method=\"ffill\")\n","            return True\n","        except:\n","            return False\n","\n","    @classmethod\n","    # 特徴量作成のメソッドをここに記入する\n","    def make_feature(cls):\n","        # df:特徴量のデータフレーム\n","        cls.df = cls.wl_data[[\"date\", \"station\", \"hour\", \"value\"]].copy()\n","\n","        # 予測対象時間\n","        cls.df[\"予測対象時間\"] = cls.df[\"hour\"]\n","\n","        # 平時の水位\n","        tmp = pd.DataFrame(cls.df.groupby(\"station\")[\"value\"].median())\n","        tmp.reset_index(inplace=True)\n","        tmp.rename(columns={'value':'平時の水位'}, inplace=True)\n","        cls.df = pd.merge(cls.df, tmp, on = 'station', how='left')\n","\n","        # 当日同時刻の水位\n","        cls.df.rename(columns={'value':'当日同時刻の水位'}, inplace=True)\n","        # 平時からの水位差\n","        cls.df[\"当日同時刻の水位_平時差\"] = cls.df[\"当日同時刻の水位\"] - cls.df[\"平時の水位\"]\n","\n","        # 当日23時の水位\n","        tmp = cls.wl_data.copy()\n","        tmp = tmp.loc[tmp['hour']== 23,:]\n","        tmp = tmp[['date', 'station', 'value']]\n","        tmp.rename(columns={'value':'当日23時の水位'}, inplace=True)\n","        cls.df = pd.merge(cls.df, tmp, on = ['date', 'station'], how = 'left')\n","\n","        # 当日0時の水位\n","        tmp = cls.wl_data.copy()\n","        tmp = tmp.loc[tmp['hour']== 0,:]\n","        tmp = tmp[['date', 'station', 'value']]\n","        tmp.rename(columns={'value':'当日0時の水位'}, inplace=True)\n","        cls.df = pd.merge(cls.df, tmp, on = ['date', 'station'], how = 'left')\n","        \n","        # 当日0時から23時の変化\n","        cls.df['当日0から23時の変化'] = cls.df['当日23時の水位'] - cls.df['当日0時の水位']\n","        # 当日0時の水位は削除\n","        cls.df.drop('当日0時の水位', axis=1, inplace=True)\n","        \n","        # staition idを取得\n","        cls.df = pd.merge(cls.df, cls.station_mst[['station', 'station_id']], how='left', on=['station'])\n","        return True\n","\n","    @classmethod\n","    def train(cls):\n","        def target_df(df):\n","            # 翌日同時刻の水位(正解データ)を用意する\n","            tmp = df.copy()\n","            tmp['date'] = tmp['date'] - 1\n","            tmp = tmp [['date', 'station', 'hour', '当日同時刻の水位']]\n","            tmp.rename(columns={'当日同時刻の水位':'翌日同時刻の水位'}, inplace=True)\n","            df = pd.merge(df, tmp, on=[\"date\", \"station\", \"hour\"], how=\"left\")\n","            return df\n","        def train_test_split(df):\n","            # 学習用データとテスト用データを分割する\n","            th_date = df[\"date\"].max() - round(df[\"date\"].max() * cls.config.th_per, 0)\n","            train = df.loc[df['date'] < th_date,:]\n","            test = df.loc[df['date'] >= th_date,:]\n","            print(\"学習用データ：{}日　評価用データ：{}日\".format(th_date, df[\"date\"].max()-th_date))\n","            return train, test\n","        def sort_and_fillna(df):    \n","            # 欠損値処理を行う関数\n","            df.sort_values([\"station\", \"date\", \"hour\"], inplace=True)\n","            df.dropna(subset = ['翌日同時刻の水位'], inplace=True)\n","            df['翌日同時刻の水位'] = df['翌日同時刻の水位'].astype(float)\n","            df = df.groupby('station').apply(lambda x: x.ffill().bfill())\n","            return df\n","        def train_model():\n","            # 学習用の関数\n","            # dateごとにGroupFoldを行う\n","            group = cls.train_X['date']\n","            valid_scores = []\n","            models = []\n","            kf = GroupKFold(n_splits=cls.config.fold)\n","\n","            # GroupFold数だけループする\n","            for fold, (train_indices, valid_indices) in enumerate(kf.split(cls.train_X, cls.train_y, group)):\n","                X_train, X_valid = cls.train_X.iloc[train_indices], cls.train_X.iloc[valid_indices]\n","                y_train, y_valid = cls.train_y.iloc[train_indices], cls.train_y.iloc[valid_indices]\n","                X_train.set_index(['station', 'date', 'hour'], inplace=True)\n","                X_valid.set_index(['station', 'date', 'hour'], inplace=True)\n","                y_train.set_index(['station', 'date', 'hour'], inplace=True)\n","                y_valid.set_index(['station', 'date', 'hour'], inplace=True)\n","\n","                lgb_train = lgb.Dataset(X_train.reset_index(drop=True), y_train)\n","                lgb_valid = lgb.Dataset(X_valid.reset_index(drop=True), y_valid, reference=lgb_train)\n","                cat_list = ['station_id']\n","                model = lgb.train(\n","                        cls.config.lgb_params,\n","                        lgb_train,\n","                        categorical_feature = cat_list,\n","                        valid_sets=lgb_valid,\n","                        verbose_eval = 50,\n","                        callbacks=[lgb.early_stopping(stopping_rounds=10, verbose=True)]\n","                )\n","                y_valid['predict'] = model.predict(X_valid)\n","                score = rmse_score(y_valid, d_key1 = '翌日同時刻の水位', d_key2 = 'predict')\n","                valid_scores.append(score)\n","                models.append(model)\n","            cv_score = np.mean(valid_scores)\n","            print(f\"CV score: {cv_score}\")\n","            return models\n","\n","        def save_model(models):\n","            # モデルを保存する関数\n","            for i in range(cls.config.fold):\n","                file = os.path.join(cls.config.model_dir, \n","                                    'trained_model_' + cls.config.model_ver + '_fold_' + str(i) + '.pkl')\n","                pickle.dump(models[i], open(file, 'wb'))\n","\n","        def rmse_score(df, d_key1, d_key2):\n","            # RMSE算出用の自作関数\n","            tmp = df.copy()\n","            tmp[\"diff_\"] = tmp[d_key1] - tmp[d_key2]\n","            tmp[\"diff_\"] = tmp[\"diff_\"].apply(lambda x: x ** 2)\n","            return np.sqrt(tmp[\"diff_\"].mean())\n","\n","        # ここからが実際の学習パート\n","        cls.df = target_df(cls.df)  # 目的変数作成\n","        train, test = train_test_split(cls.df)  # テストデータを分割\n","        train = sort_and_fillna(train)  # \n","        test = sort_and_fillna(test)\n","\n","        # 予測対象のカラムを特徴量から削除する\n","        cls.train_X = train.drop(\"翌日同時刻の水位\", axis=1)\n","        cls.train_y = pd.DataFrame(train[['station', 'date', 'hour', \"翌日同時刻の水位\"]])\n","        cls.test_X = test.drop(\"翌日同時刻の水位\", axis=1)\n","        cls.test_y = pd.DataFrame(test[['station', 'date', 'hour', \"翌日同時刻の水位\"]])\n","\n","        cls.models = train_model()\n","        save_model(cls.models)\n","        \n","        # 予測結果を格納するためのnumpyを用意する\n","        predict_np = np.zeros([cls.config.fold, len(cls.test_y)])\n","        predict_np[:,:] = np.nan # いったんnullで埋める\n","        # Fold分のモデルで予測して中央値を取る\n","        cls.test_X.set_index(['station', 'date', 'hour'], inplace=True)\n","        for i in range(cls.config.fold):\n","            predict_np[i,] = cls.models[i].predict(cls.test_X)\n","        cls.test_y['predict'] = np.median(predict_np, axis=0)\n","        cls.test_y.reset_index(inplace=True)\n","\n","        # 結果を表示する\n","        tmp = rmse_score(cls.test_y, d_key1 = '翌日同時刻の水位', d_key2 = 'predict')\n","        print('予測RMSE:{:.4f}'.format(tmp))\n","        return cls.test_y\n","\n","    @classmethod\n","    def predict(cls, input):\n","        def store_data(input, key=''):\n","            # 1日毎に与えられるデータを保存する関数\n","            add_data = pd.DataFrame(input[key])\n","            add_data['date'] = input['date']\n","            # データディレクトリに、都度データを格納する\n","            # ディレクトリがなければ作成する\n","            my_dir = 'data/' + key\n","            if not os.path.exists(my_dir):\n","                os.makedirs(my_dir) \n","            # 読み込みファイルがなければ作成する\n","            if not os.path.exists(os.path.join(my_dir, 'data.csv')) or cls.first_flg == True:\n","                df = pd.DataFrame(columns=['date', 'hour', 'station', 'value'])\n","                cls.first_flg = False\n","            else:\n","                df = pd.read_csv(os.path.join(my_dir, 'data.csv'), encoding=cls.config.encoding)\n","            # 読み込んだファイルと合体させて再格納する\n","            if input['date'] > df['date'].max() or len(df) == 0:\n","                df = pd.concat([df, add_data], axis = 0)\n","                df = df.sort_values(['date', 'station', 'hour'])\n","                # 読み込みファイルサイズの都合上、読み込む日数は過去10日まで\n","                df = df.loc[df['date'] >= df['date'].max()-10,:].copy()\n","                df.to_csv(os.path.join(my_dir, 'data.csv'), index=False, encoding=cls.config.encoding)\n","\n","        def sort_and_fillna(df):    \n","            df.sort_values([\"station\", \"date\", \"hour\"], inplace=True)\n","            df = df.groupby('station', group_keys=False).apply(lambda x: x.ffill().bfill())        \n","            return df\n","\n","        def model_predict(X):\n","            # 予測用関数\n","            # 予測結果を格納するためのnumpyを用意する\n","            predict_np = np.zeros([cls.config.fold, len(X)])\n","            predict_np[:,:] = np.nan # いったんnullで埋める\n","            # Fold分のモデルで予測して中央値を取る\n","            for i in range(cls.config.fold):\n","                predict_np[i,] = cls.models[i].predict(X)\n","            return np.median(predict_np, axis=0)\n","        def fill_error(df, station_mst):\n","            # station　×　hour　全通り組み合わせを作成し、提出データに抜け漏れがないようにする\n","            df1 = pd.DataFrame({'station' : station_mst.loc[station_mst['review_tgt'] == 1, 'station'].unique()})\n","            df1[\"dummy\"] = 1\n","            df2 = pd.DataFrame({'hour' : df['hour'].unique()})\n","            df2[\"dummy\"] = 1\n","            dummy_df = pd.merge(df1, df2, on='dummy', how='outer')[['station', 'hour']]\n","            df = pd.merge(df, dummy_df, on = ['station', 'hour'], how = 'outer')\n","            return df.fillna(0)\n","\n","        # データをデータフレーム形式で格納する\n","        store_data(input, key = 'waterlevel')\n","\n","        # モデルを取得する\n","        cls.get_model(os.path.join('..', 'model'))\n","        # データを取得する\n","        _ = cls.get_store_data('data')\n","        # データを予測する\n","        cls.make_feature()\n","        cls.df = sort_and_fillna(cls.df)\n","        # 生成された特徴量DFのうち、当該日のdateのみを抽出する\n","        cls.df = cls.df.loc[cls.df['date'] == input['date']]\n","        predict = cls.df.copy()        \n","        predict.set_index(['date', 'station', 'hour'], inplace=True)\n","        predict['value'] = model_predict(predict)\n","        predict.reset_index(inplace=True)\n","\n","        # エラー予防処理の実施\n","        predict = fill_error(predict, cls.station_mst)\n","        predict = predict[[\"station\", \"hour\", \"value\"]]\n","        prediction = predict.to_dict('records')\n","        return prediction"],"metadata":{"id":"BKOGb-ysklOR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ss = ScoringService\n","ss.get_config(my_config)\n","ss.get_store_data(my_config.data_dir)\n","ss.make_feature()\n","ss.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jp8v7f1oogD5","outputId":"27d65ec7-f182-40f5-cee7-32bac3701a0d","executionInfo":{"status":"ok","timestamp":1673361881164,"user_tz":-540,"elapsed":139226,"user":{"displayName":"Kodai Shimizu","userId":"11388889893078731648"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["学習用データ：1752.0日　評価用データ：438.0日\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  return func(*args, **kwargs)\n","<ipython-input-37-26228431de04>:117: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df['翌日同時刻の水位'] = df['翌日同時刻の水位'].astype(float)\n","/usr/local/lib/python3.8/dist-packages/lightgbm/basic.py:1208: UserWarning: categorical_feature in Dataset is overridden.\n","New categorical_feature is ['station_id']\n","  warnings.warn('categorical_feature in Dataset is overridden.\\n'\n","/usr/local/lib/python3.8/dist-packages/lightgbm/basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n","  warnings.warn('categorical_feature in param dict is overridden.')\n"]},{"output_type":"stream","name":"stdout","text":["Training until validation scores don't improve for 10 rounds.\n","[50]\tvalid_0's rmse: 0.601814\n","Early stopping, best iteration is:\n","[56]\tvalid_0's rmse: 0.598945\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-37-26228431de04>:148: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  y_valid['predict'] = model.predict(X_valid)\n"]},{"output_type":"stream","name":"stdout","text":["Training until validation scores don't improve for 10 rounds.\n","[50]\tvalid_0's rmse: 0.645898\n","Early stopping, best iteration is:\n","[75]\tvalid_0's rmse: 0.635065\n","Training until validation scores don't improve for 10 rounds.\n","[50]\tvalid_0's rmse: 0.302608\n","[100]\tvalid_0's rmse: 0.271366\n","Did not meet early stopping. Best iteration is:\n","[91]\tvalid_0's rmse: 0.270886\n","CV score: 0.5016319190736506\n","予測RMSE:0.1034\n"]},{"output_type":"execute_result","data":{"text/plain":["           index station  date  hour  翌日同時刻の水位   predict\n","0          42048      七宝  1752     0      1.71  1.678519\n","1          42049      七宝  1752     1      1.72  1.678519\n","2          42050      七宝  1752     2      1.73  1.678519\n","3          42051      七宝  1752     3      1.72  1.675341\n","4          42052      七宝  1752     4      1.70  1.668540\n","...          ...     ...   ...   ...       ...       ...\n","1744987  8728915   黒滝(国)  2189    19      0.24  0.455082\n","1744988  8728916   黒滝(国)  2189    20      0.24  0.459495\n","1744989  8728917   黒滝(国)  2189    21      0.24  0.459495\n","1744990  8728918   黒滝(国)  2189    22      0.24  0.443375\n","1744991  8728919   黒滝(国)  2189    23      0.24  0.455035\n","\n","[1744992 rows x 6 columns]"],"text/html":["\n","  <div id=\"df-6731c41a-7726-4dce-9e56-bc1e3168ed01\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>station</th>\n","      <th>date</th>\n","      <th>hour</th>\n","      <th>翌日同時刻の水位</th>\n","      <th>predict</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>42048</td>\n","      <td>七宝</td>\n","      <td>1752</td>\n","      <td>0</td>\n","      <td>1.71</td>\n","      <td>1.678519</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>42049</td>\n","      <td>七宝</td>\n","      <td>1752</td>\n","      <td>1</td>\n","      <td>1.72</td>\n","      <td>1.678519</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>42050</td>\n","      <td>七宝</td>\n","      <td>1752</td>\n","      <td>2</td>\n","      <td>1.73</td>\n","      <td>1.678519</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>42051</td>\n","      <td>七宝</td>\n","      <td>1752</td>\n","      <td>3</td>\n","      <td>1.72</td>\n","      <td>1.675341</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>42052</td>\n","      <td>七宝</td>\n","      <td>1752</td>\n","      <td>4</td>\n","      <td>1.70</td>\n","      <td>1.668540</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1744987</th>\n","      <td>8728915</td>\n","      <td>黒滝(国)</td>\n","      <td>2189</td>\n","      <td>19</td>\n","      <td>0.24</td>\n","      <td>0.455082</td>\n","    </tr>\n","    <tr>\n","      <th>1744988</th>\n","      <td>8728916</td>\n","      <td>黒滝(国)</td>\n","      <td>2189</td>\n","      <td>20</td>\n","      <td>0.24</td>\n","      <td>0.459495</td>\n","    </tr>\n","    <tr>\n","      <th>1744989</th>\n","      <td>8728917</td>\n","      <td>黒滝(国)</td>\n","      <td>2189</td>\n","      <td>21</td>\n","      <td>0.24</td>\n","      <td>0.459495</td>\n","    </tr>\n","    <tr>\n","      <th>1744990</th>\n","      <td>8728918</td>\n","      <td>黒滝(国)</td>\n","      <td>2189</td>\n","      <td>22</td>\n","      <td>0.24</td>\n","      <td>0.443375</td>\n","    </tr>\n","    <tr>\n","      <th>1744991</th>\n","      <td>8728919</td>\n","      <td>黒滝(国)</td>\n","      <td>2189</td>\n","      <td>23</td>\n","      <td>0.24</td>\n","      <td>0.455035</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1744992 rows × 6 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6731c41a-7726-4dce-9e56-bc1e3168ed01')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6731c41a-7726-4dce-9e56-bc1e3168ed01 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6731c41a-7726-4dce-9e56-bc1e3168ed01');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":[],"metadata":{"id":"oWhECTgSoy6j"},"execution_count":null,"outputs":[]}]}